[{"categories":["DL"],"content":"等待更新！ ","date":"2021-12-03","objectID":"/resnet/:0:0","series":["分类问题"],"tags":[],"title":"分类问题-ResNet","uri":"/resnet/#"},{"categories":["DL"],"content":"等待更新！ ","date":"2021-12-03","objectID":"/vgg/:0:0","series":["分类问题"],"tags":[],"title":"分类问题-VGG","uri":"/vgg/#"},{"categories":["DL"],"content":"等待更新！ ","date":"2021-12-03","objectID":"/alexnet/:0:0","series":["分类问题"],"tags":[],"title":"分类问题-AlexNet","uri":"/alexnet/#"},{"categories":["DL"],"content":"等待更新！ ","date":"2021-12-03","objectID":"/lenet/:0:0","series":["分类问题"],"tags":[],"title":"分类问题-LeNet","uri":"/lenet/#"},{"categories":["DL"],"content":"等待更新！ ","date":"2021-12-03","objectID":"/mlp/:0:0","series":["分类问题"],"tags":[],"title":"分类问题-MLP","uri":"/mlp/#"},{"categories":["DL"],"content":"主要是目前我所学习到的方向，后续会持续更新。 ","date":"2021-12-03","objectID":"/outline/:0:0","series":[],"tags":[],"title":"DL-汇总","uri":"/outline/#"},{"categories":["DL"],"content":"主要方向 以下是目前我所学习到的内容: 分类问题 目标检测问题 ","date":"2021-12-03","objectID":"/outline/:1:0","series":[],"tags":[],"title":"DL-汇总","uri":"/outline/#主要方向"},{"categories":["DL"],"content":"1 分类问题 主要理解MLP（多层感知机）到CNN（卷积神经网络）的过程，以及MLP实现过程中所涉及到的知识。而CNN应该主要理解LeNet网络的思想（解决掉了MLP的什么问题），其余后面的CNN网络就都好理解了。 ","date":"2021-12-03","objectID":"/outline/:2:0","series":[],"tags":[],"title":"DL-汇总","uri":"/outline/#1-分类问题"},{"categories":["DL"],"content":"1.1 MLP tensorflow实现版本 ","date":"2021-12-03","objectID":"/outline/:2:1","series":[],"tags":[],"title":"DL-汇总","uri":"/outline/#11-mlp"},{"categories":["DL"],"content":"1.2 CNN 1.2.1 LeNet 1.2.2 AlexNet 1.2.3 VGG 1.2.4 ResNet ","date":"2021-12-03","objectID":"/outline/:2:2","series":[],"tags":[],"title":"DL-汇总","uri":"/outline/#12-cnn"},{"categories":["DL"],"content":"1.2 CNN 1.2.1 LeNet 1.2.2 AlexNet 1.2.3 VGG 1.2.4 ResNet ","date":"2021-12-03","objectID":"/outline/:2:2","series":[],"tags":[],"title":"DL-汇总","uri":"/outline/#121-lenet"},{"categories":["DL"],"content":"1.2 CNN 1.2.1 LeNet 1.2.2 AlexNet 1.2.3 VGG 1.2.4 ResNet ","date":"2021-12-03","objectID":"/outline/:2:2","series":[],"tags":[],"title":"DL-汇总","uri":"/outline/#122-alexnet"},{"categories":["DL"],"content":"1.2 CNN 1.2.1 LeNet 1.2.2 AlexNet 1.2.3 VGG 1.2.4 ResNet ","date":"2021-12-03","objectID":"/outline/:2:2","series":[],"tags":[],"title":"DL-汇总","uri":"/outline/#123-vgg"},{"categories":["DL"],"content":"1.2 CNN 1.2.1 LeNet 1.2.2 AlexNet 1.2.3 VGG 1.2.4 ResNet ","date":"2021-12-03","objectID":"/outline/:2:2","series":[],"tags":[],"title":"DL-汇总","uri":"/outline/#124-resnet"},{"categories":["DL"],"content":"2 目标检测问题 ","date":"2021-12-03","objectID":"/outline/:3:0","series":[],"tags":[],"title":"DL-汇总","uri":"/outline/#2-目标检测问题"},{"categories":["DL"],"content":"2.1 两阶段目标检测 2.1.1 RCNN 2.1.2 Fast RCNN 2.1.3 Faster RCNN ","date":"2021-12-03","objectID":"/outline/:3:1","series":[],"tags":[],"title":"DL-汇总","uri":"/outline/#21-两阶段目标检测"},{"categories":["DL"],"content":"2.1 两阶段目标检测 2.1.1 RCNN 2.1.2 Fast RCNN 2.1.3 Faster RCNN ","date":"2021-12-03","objectID":"/outline/:3:1","series":[],"tags":[],"title":"DL-汇总","uri":"/outline/#211-rcnn"},{"categories":["DL"],"content":"2.1 两阶段目标检测 2.1.1 RCNN 2.1.2 Fast RCNN 2.1.3 Faster RCNN ","date":"2021-12-03","objectID":"/outline/:3:1","series":[],"tags":[],"title":"DL-汇总","uri":"/outline/#212-fast-rcnn"},{"categories":["DL"],"content":"2.1 两阶段目标检测 2.1.1 RCNN 2.1.2 Fast RCNN 2.1.3 Faster RCNN ","date":"2021-12-03","objectID":"/outline/:3:1","series":[],"tags":[],"title":"DL-汇总","uri":"/outline/#213-faster-rcnn"},{"categories":["DL"],"content":"2.2 单阶段目标检测 2.2.1 SSD 2.2.2 YOLO ","date":"2021-12-03","objectID":"/outline/:3:2","series":[],"tags":[],"title":"DL-汇总","uri":"/outline/#22-单阶段目标检测"},{"categories":["DL"],"content":"2.2 单阶段目标检测 2.2.1 SSD 2.2.2 YOLO ","date":"2021-12-03","objectID":"/outline/:3:2","series":[],"tags":[],"title":"DL-汇总","uri":"/outline/#221-ssd"},{"categories":["DL"],"content":"2.2 单阶段目标检测 2.2.1 SSD 2.2.2 YOLO ","date":"2021-12-03","objectID":"/outline/:3:2","series":[],"tags":[],"title":"DL-汇总","uri":"/outline/#222-yolo"},{"categories":["DL"],"content":"2.3 多阶段目标检测 2.3.1 Cascade RCNN","date":"2021-12-03","objectID":"/outline/:3:3","series":[],"tags":[],"title":"DL-汇总","uri":"/outline/#23-多阶段目标检测"},{"categories":["DL"],"content":"2.3 多阶段目标检测 2.3.1 Cascade RCNN","date":"2021-12-03","objectID":"/outline/:3:3","series":[],"tags":[],"title":"DL-汇总","uri":"/outline/#231-cascade-rcnn"},{"categories":[],"content":"使用内存映射的方法读取大数据文件 ","date":"2021-11-30","objectID":"/1/:0:0","series":[],"tags":["c++"],"title":"内存映射文件","uri":"/1/#"},{"categories":[],"content":"相关代码 // 创建或打开文件内核对象; HANDLE fileH = CreateFile(\"data.txt\", GENERIC_READ|GENERIC_WRITE, FILE_SHARE_READ, NULL, OPEN_EXISTING, FILE_ATTRIBUTE_NORMAL, NULL); if(fileH == INVALID_HANDLE_VALUE) { cout\u003c\u003c\"error in CreateFile\"\u003c\u003cendl; return -1; } // 创建一个文件映射内核对象; HANDLE mapFileH = CreateFileMapping(fileH, NULL, PAGE_READWRITE, 0, 0, \"Resource\"); if(mapFileH == NULL) { cout\u003c\u003c\"error in CreateFileMapping\"\u003c\u003cendl; return -1; } // 将文件数据映射到进程的地址空间; char * mapH = (char *)MapViewOfFile( mapFileH, FILE_MAP_ALL_ACCESS, 0, 0, 0); if(mapH == NULL) { cout\u003c\u003c\"error in MapViewOfFile\"\u003c\u003cendl; return -1; } // 读取数据; char *buf = mapH; double k; int i = 1; while(1) { k = atof(buf); cout \u003c\u003c i \u003c\u003c \": \" \u003c\u003c k \u003c\u003c endl; if (i % 3 == 0) { buf = strstr(buf, \"\\n\"); } else { buf = strstr(buf, \" \"); } if (strstr(buf, \" \") == NULL) { cout \u003c\u003c i \u003c\u003c endl; break; } i++; } // 关闭句柄; UnmapViewOfFile(mapH); CloseHandle(mapFileH); CloseHandle(fileH); 其中 data.txt 数据如下所示（这里只是一个例子，实际处理的都是几十万几百万行数据） -0.7211251 0.0245522 123.9979 -0.3867341 0.01316716 132.9994 0 0 128 0.3809185 -0.01296916 130.9995 0.7676494 -0.02613621 131.9978 1.072957 -0.03653103 122.9953 1.477118 -0.05029155 126.9914 1.919066 -0.06533858 131.986 2.302844 -0.07840508 131.9799 2.625543 -0.08939204 128.9733 注意\r\rLPWSTR类型在MinGw下可以直接这样写，但在MSVC下会有所不同。修改如下\"data.txt\" 改为 L\"data.txt\"，“Resource” 改为 L\"Resource\"而LPWSTR类型的赋值应为LPWSTR file_name = TEXT(“data.txt”);\r\r","date":"2021-11-30","objectID":"/1/:1:0","series":[],"tags":["c++"],"title":"内存映射文件","uri":"/1/#相关代码"},{"categories":["环境配置"],"content":"使用Hugo部署静态网站到Gitee的流程 ","date":"2021-11-30","objectID":"/hugo_config/:0:0","series":[],"tags":[],"title":"环境配置-Hugo","uri":"/hugo_config/#"},{"categories":["环境配置"],"content":"1 使用Hugo部署静态网站到Gitee ","date":"2021-11-30","objectID":"/hugo_config/:1:0","series":[],"tags":[],"title":"环境配置-Hugo","uri":"/hugo_config/#1-使用hugo部署静态网站到gitee"},{"categories":["环境配置"],"content":"1.1 Hugo安装及搭建 到官网Github地址下载，我选择的版本如下图Fig. 1.所示。 Fig. 1. hugo_extended_0.89.4\"\rFig. 1. hugo_extended_0.89.4\r 解压之后，命令行cd的此目录下，如图Fig. 2.所示。 Fig. 2. hugo dir\"\rFig. 2. hugo dir\r 注意\r\r这里my_website文件是后面创建的，不用在意。\r\r 然后输入hugo version命令，如下图Fig. 3.所示即安装成功。 Fig. 3. hugo version\"\rFig. 3. hugo version\r 输入hugo new site my_website命令，即可得到图Fig. 2.中的my_website文件。 之后就可以到官方主题中选择主题进行安装，比如我这个主题。他会教你后续的其它操作。 ","date":"2021-11-30","objectID":"/hugo_config/:1:1","series":[],"tags":[],"title":"环境配置-Hugo","uri":"/hugo_config/#11-hugo安装及搭建"},{"categories":["环境配置"],"content":"1.2 将本地博客推送到Gitee的命令流程 1. hugo --theme=(主题名) --baseUrl=\"(网页地址)\" --buildDrafts eg: hugo --theme=hugo-theme-stack --baseUrl=\"https://study777.gitee.io\" --buildDrafts 此步骤会生成public文件，里面就是后续要部署的博客。 2. cd public 3. git init 4. git add . 5. git commit -m \"(随便写)\" 6. git remote add origin (仓库地址) eg: git remote add origin https://gitee.com/study777/study777.git 如果这一步输入之后提示出错信息： fatal: remote origin already exists.表示已经执行过这一步操作了， 只需输入 git remote rm origin 之后再次输入即可。 7. git push -u origin master 如果推送出错表示远程仓库有本地没有的文件。即，两个仓库不同步，这种情况下需要利用 git pull 命令合并两个仓库。 只需输入 git pull --rebase origin master 或者这一步可以直接强制推送, 只需输入 git push -f origin master ","date":"2021-11-30","objectID":"/hugo_config/:1:2","series":[],"tags":[],"title":"环境配置-Hugo","uri":"/hugo_config/#12-将本地博客推送到gitee的命令流程"},{"categories":["环境配置"],"content":"1.3 后续更新博客的命令流程 在执行第二步之后不要把创建的public文件删除，如果删除了需重全部新执行第二步。 1. hugo --theme=hugo-theme-stack --baseUrl=\"https://study777.gitee.io\" --buildDrafts 2. cd public 3. git add . 4. git commit -m \"(随便写)\" 5. git push -f origin master 注意\r\r如果部署实在不成功就把Gitee仓库清空重新再来就行了\r\r","date":"2021-11-30","objectID":"/hugo_config/:1:3","series":[],"tags":[],"title":"环境配置-Hugo","uri":"/hugo_config/#13-后续更新博客的命令流程"},{"categories":["环境配置"],"content":"Windows下pytorch的GPU环境配置 ","date":"2021-11-29","objectID":"/pytorch_config/:0:0","series":[],"tags":[],"title":"环境配置-PyTorch","uri":"/pytorch_config/#"},{"categories":["环境配置"],"content":"1 本人配置 以下是本人电脑配置: 系统：Windows10 CPU：AMD Ryzen 7 4800H 显卡：GTX2060 注意\r\r一定要到NVIDIA官网查看你的显卡是否支持CUDA，如果不支持后面的步骤就不用看了（当然你能找到奇门办法也可以）。 如下图Fig. 1.所示，我的GTX2060显卡支持CUDA且算力为7.5。 Fig. 1. cuda-gpus\"\rFig. 1. cuda-gpus\r \r\r ","date":"2021-11-29","objectID":"/pytorch_config/:1:0","series":[],"tags":[],"title":"环境配置-PyTorch","uri":"/pytorch_config/#1-本人配置"},{"categories":["环境配置"],"content":"2 安装pytorch-gpu 如果没安装Anaconda，需先安装Anaconda，如果速度过慢可以复制下载链接到迅雷下载，或者使用清华镜像。 ","date":"2021-11-29","objectID":"/pytorch_config/:2:0","series":[],"tags":[],"title":"环境配置-PyTorch","uri":"/pytorch_config/#2-安装pytorch-gpu"},{"categories":["环境配置"],"content":"2.1 预先准备 打开命令行输入nvidia-smi命令查看显卡驱动版本和CUDA版本，如下图Fig. 2.所示。 Fig. 2. nvidia\"\rFig. 2. nvidia\r 注意\r\r这里的CUDA Version只是你目前对应的显卡驱动所支持的最高CUDA版本，意思后面你不能安装比这个版本高的CUDA。\r\r ","date":"2021-11-29","objectID":"/pytorch_config/:2:1","series":[],"tags":[],"title":"环境配置-PyTorch","uri":"/pytorch_config/#21-预先准备"},{"categories":["环境配置"],"content":"2.2 创建虚拟环境 由于我后面是安装的pytorch1.8.2版本所以这里虚拟环境取的pytorch1.8，你可以取其它名字。 conda create -n pytorch1.8 python=3.7 conda activate pytorch1.8 注意\r\r目前Windows上pytorch只支持Python 3.x版本，不再支持Python 2.x版本。\r\r ","date":"2021-11-29","objectID":"/pytorch_config/:2:2","series":[],"tags":[],"title":"环境配置-PyTorch","uri":"/pytorch_config/#22-创建虚拟环境"},{"categories":["环境配置"],"content":"2.3 安装pytorch-gpu 安装pytorch-gpu非常简单，直接到pytorch官网下载即可。 这里我直接安装的LTS(1.8.2)长期支持版，如下图Fig. 3.所示。 Fig. 3. pytorch-1.8.2\"\rFig. 3. pytorch-1.8.2\r 即输入以下命令。 conda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch-lts -c conda-forge ","date":"2021-11-29","objectID":"/pytorch_config/:2:3","series":[],"tags":[],"title":"环境配置-PyTorch","uri":"/pytorch_config/#23-安装pytorch-gpu"},{"categories":["环境配置"],"content":"3 验证 在命令行输入下面命令。 python import torch torch.cuda.is_available() 结果如下图Fig. 4.所示，就证明安装成功。 Fig. 4. pytorch-gpu test\"\rFig. 4. pytorch-gpu test\r 注意\r\r由于前面已经执行过conda activate pytorch1.8命令，所以请确保你已经进入了pytorch1.8虚拟环境。\r\r","date":"2021-11-29","objectID":"/pytorch_config/:3:0","series":[],"tags":[],"title":"环境配置-PyTorch","uri":"/pytorch_config/#3-验证"},{"categories":["环境配置"],"content":"cuda和cudnn的安装 ","date":"2021-11-29","objectID":"/cuda_config/:0:0","series":[],"tags":[],"title":"环境配置-CUDA","uri":"/cuda_config/#"},{"categories":["环境配置"],"content":"1 本人配置 以下是本人电脑配置: 系统：Windows10 CPU：AMD Ryzen 7 4800H 显卡：GTX2060 ","date":"2021-11-29","objectID":"/cuda_config/:1:0","series":[],"tags":[],"title":"环境配置-CUDA","uri":"/cuda_config/#1-本人配置"},{"categories":["环境配置"],"content":"2 安装cuda和cudnn ","date":"2021-11-29","objectID":"/cuda_config/:2:0","series":[],"tags":[],"title":"环境配置-CUDA","uri":"/cuda_config/#2-安装cuda和cudnn"},{"categories":["环境配置"],"content":"2.1 安装cuda 摘要\r\rCUDA(Compute Unified Device Architecture)，具体详细解释可以网上去查。总之CUDA就是一个并行计算架构，可以提升你GPU处理复杂计算的能力，也就是加速你程序运行速度。因为图像处理主要就是矩阵运算，所以为了提高计算速度可以安装CUDA。而NVIDIA的GPU显卡驱动程序和CUDA是两个完全不同的概念。你只需要知道CUDA就是一个运行在GPU上的ToolKit即可。总之你电脑虽然安装了显卡驱动，但还是要安装CUDA。 首先需查看当前显卡驱动程序版本。这里由于每个电脑打开此界面的方法可能不同，需要自己到网上去查怎么查看显卡驱动程序版本。\r\r 第一步，查看显卡驱动程序版本，如下图Fig. 1.所示。 Fig. 1. 显卡驱动程序版本\"\rFig. 1. 显卡驱动程序版本\r 第二步，再到NVIDIA官网查看显卡信息对照CUDA Toolkit and Compatible Versions表。由于我们的显卡驱动程序版本是 471.11，所以这里选择CUDA 11.4.0及以下版本即可。如图Fig. 2.所示。 Fig. 2. CUDA Toolkit and Compatible Versions表\"\rFig. 2. CUDA Toolkit and Compatible Versions表\r 第四步，下载下来，一路确定即可。 第三步，再到此网址选择CUDA 11.4.0及以下版本进行下载（由于之前我安装过一次，选择的是CUDA 11.1版本），如下图Fig. 3.所示。 Fig. 3. CUDA 11.1\"\rFig. 3. CUDA 11.1\r 注意\r\r由于这个小版本号可能过一段时间会更新，因为我以前安装的时候是11.1.7_455.06版本，但不用担心，只要大版本号（比如这里的11.1）一致就行。\r\r 第四步，下载下来，一路确定即可。 ","date":"2021-11-29","objectID":"/cuda_config/:2:1","series":[],"tags":[],"title":"环境配置-CUDA","uri":"/cuda_config/#21-安装cuda"},{"categories":["环境配置"],"content":"2.2 安装cudnn 第一步，到此界面下载与cudn大版本号对应的版本，如下图Fig. 4.所示。 Fig. 4. CUDNN 8.1.1\"\rFig. 4. CUDNN 8.1.1\r 注意\r\r需要说的是，这里图Fig. 5.虽然显示的是windows x86，但下载下来的是x64。所以不用担心，直接下载即可。 Fig. 5. windows x86\"\rFig. 5. windows x86\r \r\r 第二步，把下载下来的包解压之后，将里面的bin、include、lib文件直接复制到CUDA的安装目录下，直接覆盖即可。如下图Fig. 6.所示 Fig. 6. CUDA安装目录\"\rFig. 6. CUDA安装目录\r ","date":"2021-11-29","objectID":"/cuda_config/:2:2","series":[],"tags":[],"title":"环境配置-CUDA","uri":"/cuda_config/#22-安装cudnn"},{"categories":["环境配置"],"content":"3 验证 打开命令行输入nvcc -V，显示类似如下图Fig. 7.结果就行 Fig. 7. nvcc\"\rFig. 7. nvcc\r ","date":"2021-11-29","objectID":"/cuda_config/:3:0","series":[],"tags":[],"title":"环境配置-CUDA","uri":"/cuda_config/#3-验证"},{"categories":["环境配置"],"content":"Windows下tensorflow的GPU环境配置 ","date":"2021-11-29","objectID":"/tensorflow_config/:0:0","series":[],"tags":[],"title":"环境配置-TensorFlow","uri":"/tensorflow_config/#"},{"categories":["环境配置"],"content":"1 本人配置 以下是本人电脑配置: 系统：Windows10 CPU：AMD Ryzen 7 4800H 显卡：GTX2060 注意\r\r一定要到NVIDIA官网查看你的显卡是否支持CUDA，如果不支持后面的步骤就不用看了（当然你能找到奇门办法也可以）。 如下图Fig. 1.所示，我的GTX2060显卡支持CUDA且算力为7.5。 Fig. 1. cuda-gpus\"\rFig. 1. cuda-gpus\r \r\r ","date":"2021-11-29","objectID":"/tensorflow_config/:1:0","series":[],"tags":[],"title":"环境配置-TensorFlow","uri":"/tensorflow_config/#1-本人配置"},{"categories":["环境配置"],"content":"2 安装tensorflow-gpu 如果没安装Anaconda，需先安装Anaconda，如果速度过慢可以复制下载链接到迅雷下载，或者使用清华镜像。 ","date":"2021-11-29","objectID":"/tensorflow_config/:2:0","series":[],"tags":[],"title":"环境配置-TensorFlow","uri":"/tensorflow_config/#2-安装tensorflow-gpu"},{"categories":["环境配置"],"content":"2.1 预先准备 打开命令行输入nvidia-smi命令查看显卡驱动版本和CUDA版本，如下图Fig. 2.所示。 Fig. 2. nvidia\"\rFig. 2. nvidia\r 注意\r\r这里的CUDA Version只是你目前对应的显卡驱动所支持的最高CUDA版本，意思后面你不能安装比这个版本高的CUDA。\r\r 到tensorflow官网查看所想安装的tensorflow-gpu与其对应的python、cuda和cudnn版本。 由于本人安装的是tensorflow-gpu-2.3.0版本，所以后面就以这个版本为例，如下图Fig. 3.所示。 Fig. 3. tensorflow-gpu-2.3.0\"\rFig. 3. tensorflow-gpu-2.3.0\r 注意\r\r由于tensorflow函数更新比pytorch大，所以选一个中间版本能稳定使用最好（如果后面要安装其它tensorflow版本，按部就班就行）。\r\r ","date":"2021-11-29","objectID":"/tensorflow_config/:2:1","series":[],"tags":[],"title":"环境配置-TensorFlow","uri":"/tensorflow_config/#21-预先准备"},{"categories":["环境配置"],"content":"2.2 创建虚拟环境 tensorflow-gpu-2.3.0对应python版本区间为[3.5~3.8]，这里我选的3.7。 conda create -n tf2 python=3.7 conda activate tf2 ","date":"2021-11-29","objectID":"/tensorflow_config/:2:2","series":[],"tags":[],"title":"环境配置-TensorFlow","uri":"/tensorflow_config/#22-创建虚拟环境"},{"categories":["环境配置"],"content":"2.3 安装tensorflow-gpu pip install tensorflow 注意\r\r由于tensorflow-2.1及以上版本CPU和GPU软件包已经合并，不需要指定为tensorflow-gpu。\r\r ","date":"2021-11-29","objectID":"/tensorflow_config/:2:3","series":[],"tags":[],"title":"环境配置-TensorFlow","uri":"/tensorflow_config/#23-安装tensorflow-gpu"},{"categories":["环境配置"],"content":"2.4 安装cuda和cudnn 对于tensorflow-gpu-2.3.0版本来说，CUDA和CUDNN对应版本分别为10.1和7.6。 conda install cudatoolkit=10.1 conda install cudnn=7.6.5 ","date":"2021-11-29","objectID":"/tensorflow_config/:2:4","series":[],"tags":[],"title":"环境配置-TensorFlow","uri":"/tensorflow_config/#24-安装cuda和cudnn"},{"categories":["环境配置"],"content":"3 验证 查看tensorflow官网api命令，在命令行下依次输入下面命令。 python import tensorflow as tf tf.test.is_built_with_cuda() tf.test.is_built_with_gpu_support() 结果如下图Fig. 4.所示，就证明安装成功。 Fig. 4. tensorflow-gpu test\"\rFig. 4. tensorflow-gpu test\r 注意\r\r由于前面已经执行过conda activate tf2命令，所以请确保你已经进入了tf2虚拟环境。\r\r","date":"2021-11-29","objectID":"/tensorflow_config/:3:0","series":[],"tags":[],"title":"环境配置-TensorFlow","uri":"/tensorflow_config/#3-验证"},{"categories":null,"content":" You are not connected to the Internet, only cached pages will be available. ","date":"0001-01-01","objectID":"/offline/:0:0","series":null,"tags":null,"title":"Offline","uri":"/offline/#"}]